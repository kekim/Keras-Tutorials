{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02_logistic_regression.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"metadata":{"id":"Lq4-RpbdTiWH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"df2ab302-bade-4ca2-9564-ba55abd9b2d7","executionInfo":{"status":"ok","timestamp":1539852069923,"user_tz":-540,"elapsed":1494,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.optimizers import SGD\n","from keras.datasets import mnist\n","from keras.utils import np_utils"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"XR_68lyaTiWN","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size = 128\n","nb_classes = 10\n","nb_epoch = 100"],"execution_count":0,"outputs":[]},{"metadata":{"id":"V3vOBXFgTiWQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"986e7140-fb5d-4e7e-e4ee-4ee52c15cc00","executionInfo":{"status":"ok","timestamp":1539852075135,"user_tz":-540,"elapsed":3824,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["# Load MNIST dataset\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","X_train = X_train.reshape(60000, 784)\n","X_test = X_test.reshape(10000, 784)\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /= 255\n","Y_Train = np_utils.to_categorical(y_train, nb_classes)\n","Y_Test = np_utils.to_categorical(y_test, nb_classes)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"metadata":{"id":"6s6YnzM-TiWU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":179},"outputId":"2999f2ae-06df-4d54-81dd-8b2412d02a4a","executionInfo":{"status":"ok","timestamp":1539852076596,"user_tz":-540,"elapsed":1434,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["# Logistic regression model\n","model = Sequential()\n","model.add(Dense(units=10, input_shape=(784,), kernel_initializer='normal', activation='softmax'))\n","model.compile(optimizer=SGD(lr=0.05), loss='categorical_crossentropy', metrics=['accuracy'])\n","model.summary()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 10)                7850      \n","=================================================================\n","Total params: 7,850\n","Trainable params: 7,850\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"uLGkeM4HTiWY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":3617},"outputId":"b228bd64-2e92-44cb-e830-ec607b92bb9f","executionInfo":{"status":"ok","timestamp":1539852173222,"user_tz":-540,"elapsed":96572,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["# Train\n","history = model.fit(X_train, Y_Train, epochs=nb_epoch, batch_size=batch_size, verbose=1)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","60000/60000 [==============================] - 1s 17us/step - loss: 0.7160 - acc: 0.8280\n","Epoch 2/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.4325 - acc: 0.8845\n","Epoch 3/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.3860 - acc: 0.8946\n","Epoch 4/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.3623 - acc: 0.9003\n","Epoch 5/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.3474 - acc: 0.9034\n","Epoch 6/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.3368 - acc: 0.9060\n","Epoch 7/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.3286 - acc: 0.9082\n","Epoch 8/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.3221 - acc: 0.9104\n","Epoch 9/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.3169 - acc: 0.9117\n","Epoch 10/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.3125 - acc: 0.9129\n","Epoch 11/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.3086 - acc: 0.9140\n","Epoch 12/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.3052 - acc: 0.9151\n","Epoch 13/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.3024 - acc: 0.9158\n","Epoch 14/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2998 - acc: 0.9164\n","Epoch 15/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2974 - acc: 0.9168\n","Epoch 16/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2953 - acc: 0.9180\n","Epoch 17/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2935 - acc: 0.9189\n","Epoch 18/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2916 - acc: 0.9191\n","Epoch 19/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2899 - acc: 0.9190\n","Epoch 20/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2885 - acc: 0.9194\n","Epoch 21/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2871 - acc: 0.9204\n","Epoch 22/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2858 - acc: 0.9206\n","Epoch 23/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2846 - acc: 0.9211\n","Epoch 24/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2834 - acc: 0.9212\n","Epoch 25/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2824 - acc: 0.9213\n","Epoch 26/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2813 - acc: 0.9222\n","Epoch 27/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2803 - acc: 0.9223\n","Epoch 28/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2793 - acc: 0.9226\n","Epoch 29/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2785 - acc: 0.9228\n","Epoch 30/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2777 - acc: 0.9230\n","Epoch 31/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2770 - acc: 0.9234\n","Epoch 32/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2762 - acc: 0.9240\n","Epoch 33/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2755 - acc: 0.9236\n","Epoch 34/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2748 - acc: 0.9241\n","Epoch 35/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2742 - acc: 0.9243\n","Epoch 36/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2735 - acc: 0.9243\n","Epoch 37/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2728 - acc: 0.9247\n","Epoch 38/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2721 - acc: 0.9244\n","Epoch 39/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2716 - acc: 0.9249\n","Epoch 40/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2712 - acc: 0.9249\n","Epoch 41/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2707 - acc: 0.9252\n","Epoch 42/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2701 - acc: 0.9256\n","Epoch 43/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2695 - acc: 0.9257\n","Epoch 44/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2692 - acc: 0.9254\n","Epoch 45/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2687 - acc: 0.9258\n","Epoch 46/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2682 - acc: 0.9258\n","Epoch 47/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2678 - acc: 0.9261\n","Epoch 48/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2673 - acc: 0.9262\n","Epoch 49/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2669 - acc: 0.9261\n","Epoch 50/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2664 - acc: 0.9265\n","Epoch 51/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2661 - acc: 0.9265\n","Epoch 52/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2657 - acc: 0.9268\n","Epoch 53/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2654 - acc: 0.9264\n","Epoch 54/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2649 - acc: 0.9268\n","Epoch 55/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2646 - acc: 0.9271\n","Epoch 56/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2643 - acc: 0.9272\n","Epoch 57/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2640 - acc: 0.9272\n","Epoch 58/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2636 - acc: 0.9272\n","Epoch 59/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2633 - acc: 0.9274\n","Epoch 60/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2629 - acc: 0.9277\n","Epoch 61/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2627 - acc: 0.9276\n","Epoch 62/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2623 - acc: 0.9273\n","Epoch 63/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2621 - acc: 0.9278\n","Epoch 64/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2617 - acc: 0.9279\n","Epoch 65/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2615 - acc: 0.9280\n","Epoch 66/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2612 - acc: 0.9278\n","Epoch 67/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2608 - acc: 0.9281\n","Epoch 68/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2606 - acc: 0.9280\n","Epoch 69/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2604 - acc: 0.9282\n","Epoch 70/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2601 - acc: 0.9283\n","Epoch 71/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2599 - acc: 0.9283\n","Epoch 72/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2597 - acc: 0.9288\n","Epoch 73/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2595 - acc: 0.9286\n","Epoch 74/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2592 - acc: 0.9285\n","Epoch 75/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2590 - acc: 0.9285\n","Epoch 76/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2587 - acc: 0.9290\n","Epoch 77/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2585 - acc: 0.9292\n","Epoch 78/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2582 - acc: 0.9286\n","Epoch 79/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2581 - acc: 0.9288\n","Epoch 80/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2578 - acc: 0.9291\n","Epoch 81/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2576 - acc: 0.9291\n","Epoch 82/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2573 - acc: 0.9288\n","Epoch 83/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2571 - acc: 0.9294\n","Epoch 84/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2570 - acc: 0.9291\n","Epoch 85/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2568 - acc: 0.9294\n","Epoch 86/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2566 - acc: 0.9295\n","Epoch 87/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2563 - acc: 0.9293\n","Epoch 88/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2561 - acc: 0.9293\n","Epoch 89/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2560 - acc: 0.9297\n","Epoch 90/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2558 - acc: 0.9295\n","Epoch 91/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2556 - acc: 0.9296\n","Epoch 92/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2554 - acc: 0.9297\n","Epoch 93/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2553 - acc: 0.9295\n","Epoch 94/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2550 - acc: 0.9296\n","Epoch 95/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2549 - acc: 0.9301\n","Epoch 96/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2547 - acc: 0.9301\n","Epoch 97/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2546 - acc: 0.9299\n","Epoch 98/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2542 - acc: 0.9300\n","Epoch 99/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2542 - acc: 0.9299\n","Epoch 100/100\n","60000/60000 [==============================] - 1s 16us/step - loss: 0.2540 - acc: 0.9300\n"],"name":"stdout"}]},{"metadata":{"id":"ilB1OnXJTiWc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"d0edeebe-ce6a-4f20-b01b-03ffbbca475e","executionInfo":{"status":"ok","timestamp":1539852175293,"user_tz":-540,"elapsed":2035,"user":{"displayName":"Keeeung Kim","photoUrl":"","userId":"02647300226657852643"}}},"cell_type":"code","source":["# Evaluate\n","evaluation = model.evaluate(X_test, Y_Test, verbose=1)\n","print('Summary: Loss over the test dataset: %.2f, Accuracy: %.2f' % (evaluation[0], evaluation[1]))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["10000/10000 [==============================] - 0s 25us/step\n","Summary: Loss over the test dataset: 0.27, Accuracy: 0.93\n"],"name":"stdout"}]}]}